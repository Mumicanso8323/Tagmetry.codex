# Diffusion/LoRA微調整向け 画像データセットのタグ分布ヘルスチェック研究

## 背景

画像生成の拡散モデル（diffusion）をタグ（キャプション）付き画像コーパスで微調整する場合、学習は「画像と、その画像を生成すべきテキスト」の対応を前提に進みます。Kohya系の学習スクリプトでは、画像と同名のキャプションファイルを置き、その内容（多くはカンマ区切りタグ）を学習時のプロンプトとして使う、という運用が一般的です。citeturn11search15turn12search1  
この前提が崩れる（タグが偏る・誤る・重複が多い）と、微調整後の出力品質が悪化し得ることは、近年の研究でも繰り返し示唆されています。たとえば diffusion を「不均衡な画像‐テキスト対」で学習・微調整すると性能が劣化し得る、という問題意識が明示されています。citeturn10search2turn10search6 また、LoRAなどのパラメータ効率微調整（PEFT）でも「微調整データの品質」への依存が大きいことが指摘されています。citeturn10search0  

さらに実務上、タグ列が長いと**テキストエンコーダの最大長で切り捨て**が起き、実際に学習に入るタグ分布が「意図した分布」とズレます。Stable Diffusion系の多くは CLIP 系テキストエンコーダを使い、プロンプトが 77 tokens を超えると後半が切り捨てられる、という解説・実装上の前提が広く共有されています。citeturn12search3turn8search15  
したがって「タグ分布を測って健康度（health）をスコアリングし、介入（再配分・ノイズ除去・カテゴリ分割）を提案する」には、**分布の偏り**・**タグの有用性**・**共起構造**・**ノイズ/重複**・**実際の学習時に有効なタグ長**を同時に見る必要があります。

## 評価対象の定義

本レポートでは、画像データセットを以下のように抽象化します。

- 画像 \(i=1..N\) に対し、タグ集合（または順序付きリスト） \(T_i\) が付く（例：カンマ区切り）。citeturn11search15turn12search1  
- タグ頻度には少なくとも2種類がある  
  - **出現回数ベース（token-count）**：タグが何回出たか（同一画像内での重複も数える）  
  - **画像カバレッジベース（document frequency）**：何枚の画像にそのタグが含まれるか（1画像に何回出ても1と数える）  
  TF‑IDF などは後者（文書頻度）を使うのが自然です。citeturn0search2  

以降のメトリクスはどちらの集計でも定義できますが、**実務では「画像カバレッジ」と「出現回数」の両方を計測してズレを見る**のが頑健です（同一画像で同じタグが重複している、などの異常を拾えるため）。

## 候補メトリクスのショートリスト

以下は「消費者向けプロダクトで説明可能」「拡散/LoRA微調整の失敗要因に直結しやすい」「計算コストが現実的」を重視して選んだ **11個**の候補メトリクスです（要件の8–12に収まるように調整）。

image_group{"layout":"carousel","aspect_ratio":"16:9","query":["Lorenz curve Gini coefficient diagram","long tail distribution Zipf plot rank frequency","co-occurrence network graph modularity communities"],"num_per_query":1}

### M1 正規化エントロピー（タグ多様性）

**定義**  
タグの確率分布 \(p(t)\)（例：全タグ出現のうちタグ \(t\) の割合）に対し、情報エントロピー  
\[
H(p)=-\sum_t p(t)\log p(t)
\]
を計算し、最大値 \(\log |V|\)（\(|V|\) はタグ種類数）で割って **正規化**：  
\[
H_\text{norm}=\frac{H(p)}{\log |V|}\in[0,1]
\]
citeturn0search0turn0search9  

**直感**  
- 1に近い：多くのタグがバランスよく出る  
- 0に近い：少数タグが支配（“同じことばかり書いてある”）

**良い点**  
- 1つの数値で「偏り」を直感的に表現でき、説明もしやすい。citeturn0search0  
- ロングテールの度合いを、タグ種類数が違うデータセット間でも比較しやすい（正規化するため）。

**弱点・失敗モード**  
- \(|V|\)（タグ種類数）が巨大で、ノイズ的なレアタグが大量にあると、実態より高く見える場合がある（“見かけの多様性”）。  
- 同義語・表記ゆれでタグが分裂すると多様性が過大評価される（例：「red hair」「red-hair」）。

**計算コスト**  
- タグ頻度カウントが \(O(\sum_i |T_i|)\)、エントロピー計算が \(O(|V|)\)。実務ではほぼ線形。

---

### M2 有効タグ数（Effective number / Perplexity風の解釈）

**定義**  
エントロピーから「同じ多様性を持つ“等確率タグ数”」に変換：  
\[
N_\text{eff}=\exp(H(p))
\]
（対数底が2なら \(2^{H}\)）。これは perplexity が「エントロピーの指数」である、という関係と同じ発想です。citeturn4search1turn4search4  

**直感**  
「あなたのデータセットは、実質的に“均等に出るタグが何種類”ぶんの情報量か？」という言い方ができます。エントロピー値より非専門家に伝わりやすいことが多いです。citeturn4search1  

**良い点**  
- プロダクトUIで説明が簡単：「実質◯種類しか機能していない」。  
- M1よりも操作感が掴みやすい（例えば 10→20 は“2倍”の増加として理解できる）。

**弱点・失敗モード**  
- M1と情報的に近い（派生量）ので、スコアモデルでは**重み付けに注意**（二重計上しやすい）。  
- ノイズタグの大量追加で大きくなってしまう点はM1と同様。

**計算コスト**  
- M1の結果を再利用でき、追加コストほぼゼロ。

---

### M3 ジニ係数（不平等度）

**定義**  
タグ頻度（またはタグカバレッジ）の配列に対してローレンツ曲線を考え、完全平等（全タグが同じ頻度）からの乖離を 0–1 で表す指標。0が完全平等、1が最大不平等。citeturn0search4turn5search2  

**直感**  
「上位タグがどれだけ“独占”しているか」を直感的に捉えます（エントロピーより“格差”の比喩が効く）。citeturn0search4  

**良い点**  
- “上位が取りすぎ”を強く反映し、ロングテールの偏り検知に強い。  
- ローレンツ曲線とセットで可視化すると説得力が高い。citeturn0search4turn5search2  

**弱点・失敗モード**  
- “どのタグが問題か”の特定には別の局所指標（M5など）が必要。  
- ノイズタグで裾野が増えると、解釈が難しくなることがある。

**計算コスト**  
- タグ頻度をソートして累積を取るため \(O(|V|\log|V|)\)。多くのデータセットで実務上十分。

---

### M4 HHI（集中度）または Simpson 系（\(\sum p^2\)）

**定義**  
確率分布 \(p(t)\) に対して  
\[
\text{HHI}=\sum_t p(t)^2
\]
（市場集中度ではシェアの2乗和）で、支配的な要素があると大きくなります。米国司法省の説明でも「各シェアを2乗して合計」と定義されています。citeturn4search6turn4search3  
同じ式は生態学では Simpson 指数としても現れます。citeturn5search7turn5search0  

**直感**  
「ランダムに2回タグを引いたら同じタグになる確率」に対応し、支配タグがあると急増します。citeturn5search7  

**良い点**  
- 上位タグの支配を非常に敏感に検知（エントロピーより“支配”に鋭い）。  
- **スケールを 10,000 倍（\(\times 10000\)）**すると、市場集中度の慣習的な目安（1500/2500など）を“比喩として”利用しやすい。citeturn4search6  

**弱点・失敗モード**  
- 逆に「中位タグの分布形状」はあまり見えない。  
- “タグ種類数が多いが上位が支配”のとき、M1と結論が一致しやすい（冗長）。

**計算コスト**  
- \(O(|V|)\)。

---

### M5 ヘッド支配率（Top‑k mass / Top‑1 share）

**定義**  
上位 \(k\) タグの確率質量の合計：
\[
\text{TopK}(k)=\sum_{t\in \text{Top-}k} p(t)
\]
特に **Top‑1（最頻タグ比率）** と **Top‑10** は説明しやすい。

**直感**  
「一番多いタグが全体の何％？」「上位10個で何％？」という、非専門家が最も理解しやすい形です（ジニやエントロピーの“原因タグ”を特定するのにも使えます）。

**良い点**  
- “犯人タグ”がすぐ分かり、介入提案に直結しやすい。  
- UI表示（警告文）に向いている。

**弱点・失敗モード**  
- ロングテール全体の形状を見落とす（Top‑1が低くても長い尾がある等）。  
- タグの粒度（粗い/細かい）に影響される。

**計算コスト**  
- 頻度ソートが必要なら \(O(|V|\log|V|)\)。ヒストグラム上位抽出は実務上高速。

---

### M6 目標分布への距離（JSD推奨、KLは補助）

**定義**  
「理想のタグ分布」 \(q(t)\) を用意して、実データ \(p(t)\) との距離を測ります。  
- **KLダイバージェンス**：  
\[
D_{KL}(p\|q)=\sum_t p(t)\log\frac{p(t)}{q(t)}
\]
ただし \(q(t)=0\) で \(p(t)>0\) の場合は発散し得ます（定義域の制約）。citeturn2search0  
- **Jensen–Shannon divergence（JSD）**：KLを対称化・平滑化した形で、**対称**かつ**常に有限**という利点があります。citeturn2search1  
（対数底2ならJSDは0〜1に収まる、という扱いがしやすいことが多いです。）

**直感**  
“あなたの目標（例えば『髪色は均等にしたい』『背景は屋外:屋内=7:3にしたい』）から、現状はどれだけズレているか”。

**良い点**  
- 「ターゲットを満たしているか」を明確に数値化でき、リコメンド（サンプリング/重み付け）に直結。  
- JSDはゼロ割・無限大の扱いが起きにくく、プロダクトで安全。citeturn2search1turn2search0  

**弱点・失敗モード**  
- **目標分布 \(q(t)\) の設計が難しい**：ユーザーが望む世界観に依存し、正解が一意でない。  
- ラベル体系が揺れている（同義語分裂）と距離が過大評価される。

**計算コスト**  
- \(O(|V|)\)。ただし \(q(t)\) を作るUI/ロジックが別途必要。

---

### M7 TF‑IDF風の「識別性スコア」とストップタグ候補検出

**定義**  
TF‑IDF は「文書内頻度（TF）」と「希少性（IDF）」で語の重要度を定義する古典的手法です。citeturn0search2  
タグの場合は、各画像を文書、各タグを語とみなして  
\[
\mathrm{idf}(t)=\log\frac{N}{n_t}
\]
（\(n_t\)はタグ \(t\) を含む画像枚数）を計算し、  
- データセット全体として「低IDFタグ（どこにでも出るタグ）」が多すぎないか  
- 逆に「高IDFタグ（ほぼ単発）」が多すぎないか  
を見ます。

**直感**  
- IDFが低いタグ＝“説明力が薄い共通語”（ストップワード/ストップタグに近い）  
- IDFが高すぎるタグ＝“固有すぎて再現性が低い/ノイズかも”

**良い点**  
- “削るべきタグ”“まとめるべきタグ”の候補を機械的に出せる。  
- 目標が「特定キャラ/特定スタイル」なら、IDFが中〜高のタグが適切にあるかを確認できる。

**弱点・失敗モード**  
- 本当に重要な一般タグ（例：「portrait」）も低IDFになり得る。消すべきとは限らない。  
- TF‑IDFは本来、検索・ランキング用途の重み付けであり、**生成モデル学習での最適解を保証しない**（あくまでヒューリスティクス）。citeturn0search2  

**計算コスト**  
- \(O(\sum_i |T_i|)\) で \(n_t\) を数えれば十分。実務は線形。

---

### M8 共起の強さ（PMI / Lift）と「異常共起」検出

**定義**  
タグ \(x,y\) の共起度合いを  
- **PMI**：  
\[
\mathrm{PMI}(x,y)=\log\frac{p(x,y)}{p(x)p(y)}
\]
と定義（独立なら0、期待以上に一緒に出るほど正）。citeturn2search3turn2search7  
- **Lift**（アソシエーションルールの指標）：  
\[
\mathrm{Lift}(X\to Y)=\frac{P(X\land Y)}{P(X)P(Y)}
\]
で、1より大きいと“独立より一緒に出やすい”。citeturn6search3  

**直感**  
「その2タグは“セット売り”になっていないか？」  
- 良いセット：`(black hair, ponytail)` など、意味的に納得  
- 悪いセット：本来独立のはずが常に一緒→データ収集バイアス、誤タグ、カテゴリ混在のサイン

**良い点**  
- **誤タグ・混在**の早期検知に強い（例：`indoor` が `beach` と強共起）。  
- クラスタリング（M9）前の“エッジ抽出”として使いやすい。

**弱点・失敗モード**  
- PMI/Liftは**レアタグに過敏**になりやすい（分母が小さく、極端な値が出る）。citeturn6search3turn2search7  
- 対策として「最低出現数（例：\(n_t\ge 20\)）でフィルタ」「PMIの上限クリップ」が必要。

**計算コスト**  
- 1画像あたりのタグ数を平均 \(L\) とすると、共起カウントは概ね \(O(NL^2)\)。  
- 実務では「上位Mタグだけ」「同一画像内ペアだけハッシュ集計」「疎行列」で削減。

---

### M9 共起グラフのコミュニティ性（モジュラリティ）とカテゴリ分割提案

**定義**  
タグをノード、強い共起（例：PMIが閾値以上）をエッジとするグラフを作り、コミュニティ分割の“良さ”を **モジュラリティ**で評価します。モジュラリティ最大化はコミュニティ構造の有効な手法として古典的に扱われています。citeturn2search2turn2search6  

**直感**  
グラフが「いくつかの塊」に分かれるほど、あなたのデータセットは**複数カテゴリの混合**になっている可能性が高い。混合が強いと、単一LoRAに“相反する特徴”を同時に覚えさせて不安定になりやすく、**分割（複数LoRA/複数トリガー）**が有効なことがあります（実務上の提案）。  

**良い点**  
- “分割した方がよいか”を、タグ分布の構造から機械的に提案できる。  
- 「カテゴリAとBが混ざっている」理由を、グラフ可視化で説明しやすい。citeturn2search2  

**弱点・失敗モード**  
- グラフ構築（どのエッジを張るか）が恣意的になりやすい（PMI閾値、Top‑M制限など）。citeturn2search2turn2search7  
- モジュラリティは“分割が良い”ことを示すが、それが必ずしも「学習を分けるべき」ことを保証しない（最終判断は目的依存）。

**計算コスト**  
- エッジ数を \(E\) とすると、一般にコミュニティ検出は \(O(E)\)〜準線形のアルゴリズムが多いが、設定に依存。  
- 消費者向けでは「上位タグのみ」「エッジ数を制限」して安定化させるのが現実的。

---

### M10 近重複率（Near-duplicate）による“見かけのタグ分布”の歪み検知

**定義**  
画像が重複・近重複（同一画像のリサイズ/圧縮/軽微編集、連写）だと、タグ頻度が人工的に増え、LoRAが特定パターンを過学習しやすくなります（一般に重複検出が重要とされる領域）。近重複検出には、画像の内容に頑健な **perceptual hashing**（aHash/pHash/dHash等）を使う方法が広く知られています。citeturn3search1turn1search3  
実装例として imagehash は複数の perceptual hash を提供し、近似比較（ハミング距離）で類似判定します。citeturn3search1  

加えて、テキスト側も重複があるので、キャプション/タグ文字列の近重複には SimHash 系が大規模重複検出で使われます。citeturn3search2  

**直感**  
「枚数は多いのに、実は同じ絵が何度も入っている」＝タグ分布も学習信号も水増し。

**良い点**  
- タグ分布の健康診断として、非常に“効く”現場問題（重複）に直結。  
- 画像hashは軽量で、GPU不要で回せることが多い。citeturn3search1turn1search3  

**弱点・失敗モード**  
- perceptual hash は回転・大きなクロップ・大幅な構図変更には弱い場合がある（手法依存）。citeturn1search3  
- 逆に“似た構図の別画像”（シリーズ物）を重複扱いしてしまうリスクもある。  
- ベストプラクティスは「hashで候補抽出→人手/埋め込みで再確認」。

**計算コスト**  
- 画像hash生成：\(O(N)\)（各画像を小さくして特徴抽出）。citeturn3search1  
- 全ペア比較は \(O(N^2)\) なので、実務ではハッシュのバケット化/ANNが必要。

---

### M11 タグと画像の整合性（CLIPScore系）＋ トークン長超過率

**定義**  
1) **整合性スコア（image–text alignment）**  
CLIP は画像とテキストを同一埋め込み空間に置き、対応するペアが近くなるよう学習するモデルです。citeturn3search3turn3search7  
この性質を使い、画像埋め込みとテキスト埋め込みのコサイン類似度で「整合性」を測れます。CLIPScore は、参照文なしで画像‐キャプション整合性を評価する指標として提案されています。citeturn9search0turn9search1  
また大規模データセット構築でも、CLIP類似度で画像‐テキスト対をフィルタする運用が実際に行われています。citeturn9search3turn9search5  

2) **トークン長超過率（実際に学習に入るタグの健康度）**  
Stable Diffusion系では、入力が 77 tokens を超えると後半が切り捨てられる、という説明が一般に示されています。citeturn12search3turn8search15  
よって「キャプションが何％の画像で最大長を超えているか」「超えると何トークン分落ちるか」を測ることは、**タグ分布の実効性**の測定です。

**直感**  
- 整合性が低い：誤タグ、取り違え、ノイズ画像、説明不足  
- トークン超過が多い：後半タグは“存在しないもの”として学習され、分布評価が嘘になる

**良い点**  
- “ノイズタグ/誤対応”という致命的問題を、ある程度自動で検知できる。citeturn9search0turn9search5  
- トークン超過率は、拡散/LoRA特有の実装制約（最大長）に直結し、改善アクション（短縮、重要タグ固定、分割）へ繋がる。citeturn12search3turn8search15  

**弱点・失敗モード**  
- CLIPScore系は万能ではなく、細かな誤り（否定、文脈依存など）に弱いケースが報告されています。citeturn9search7  
- CLIP/埋め込みモデルの種類（ViT-B/32等）や言語によってスコア分布が変わり、**絶対閾値が移植しにくい**。citeturn3search7turn9search5  
- 77トークン制限はモデル/パイプラインに依存するため、製品側で“対象モデルの最大長”を正しく設定しないと誤警告になる。citeturn12search3turn8search3  

**計算コスト**  
- CLIP埋め込み：1枚あたり前向き推論（GPU推奨）。全体で概ね \(O(N)\)。citeturn3search7turn9search0  
- トークン長計測：トークナイズ \(O(\sum_i |T_i|)\) で軽量。citeturn12search3turn8search15  

## 消費者向けの Dataset Health Score 提案

ここでは「専門家がいなくても、危険なデータセットを事前に止められる」ことを優先し、**100点満点**の単純な合成スコアと、説明しやすいサブスコア（4つの柱）を提案します。なお、閾値・重みは“研究で唯一の正解がある”タイプではないため、**製品ではテレメトリ（ユーザー結果）で校正する前提の初期値**として提示します（ヒューリスティクス）。

### サブスコア設計

- **偏りスコア（Balance, 0–100）**  
  入力：M1（正規化エントロピー）、M3（ジニ）、M4（HHI）、M5（Top‑k）  
  目的：少数タグの支配（不均衡）を検知。拡散モデルが不均衡で劣化し得る問題意識に対応。citeturn10search2  

- **構造スコア（Structure, 0–100）**  
  入力：M8（PMI/Lift異常共起）、M9（モジュラリティ）  
  目的：カテゴリ混在・誤タグ・分割すべき塊を検知。コミュニティ構造をモジュラリティで捉えるのはネットワーク分析の定石。citeturn2search2turn2search7  

- **品質スコア（Quality, 0–100）**  
  入力：M11（CLIP整合性）、（必要なら）M6（目標分布との距離）  
  目的：画像‐タグ対応のノイズを検知。CLIPScoreが画像‐キャプション整合性の指標として提案され、CLIP類似度フィルタで大規模データを構築する事例もある。citeturn9search0turn9search5  
  （ノイズが学習を難しくする、という一般論も補強できます。citeturn10search1）

- **冗長性スコア（Uniqueness, 0–100）**  
  入力：M10（近重複率）、M11（トークン長超過率）  
  目的：重複と“実効タグ欠落”を検知。近重複検出に perceptual hashing や SimHash が使われることは広く知られる。citeturn3search1turn3search2turn12search3  

### 合成スコア

**Dataset Health Score（DHS）** を次で定義（初期提案）：

\[
\text{DHS}=0.35\cdot \text{Quality}+0.25\cdot \text{Balance}+0.20\cdot \text{Uniqueness}+0.20\cdot \text{Structure}
\]

重みの意図：  
- **Quality最重視**：誤対応（ノイズ）は微調整の根本を壊しやすい、という研究上の問題意識（ノイズ/不均衡の悪影響やデータ品質依存）に沿う。citeturn10search0turn10search1turn10search2  

### 閾値と非専門家向け説明文の例

**全体（DHS）**  
- **80–100（良好）**：「タグの偏り・誤り・重複が少なく、学習に使える状態」  
- **60–79（注意）**：「学習は動くが、出力が“偏る/不安定”になりやすい。いくつか手直し推奨」  
- **40–59（要改善）**：「偏り・ノイズ・重複のどれかが強い。学習前に整理しないと結果が悪化しやすい」  
- **0–39（危険）**：「データが壊れている可能性が高い。まずは修正・分割・削除を推奨」

**個別指標の“説明しやすい”初期閾値例（提案）**  
- HHI（\(\times 10000\) スケール）  
  - **<1500**：集中していない（緑）  
  - **1500–2500**：中程度に集中（黄）  
  - **>2500**：強い集中（赤）  
  これは元々、市場集中度評価での目安として提示されている区分で、タグ分布でも“集中度の比喩”として使いやすい。citeturn4search6  
- Top‑1 share  
  - **>30%**：単一タグ支配の疑い（黄）  
  - **>50%**：ほぼそのタグしか学習していない恐れ（赤）  
  （※これは製品ヒューリスティクス。ジャンル専用LoRAでは許容される場合もある。）  
- CLIP整合性（例：コサイン類似度）  
  - 「下位10パーセンタイルが極端に低い画像が多い」＝誤対応が混ざっている可能性  
  大規模データセットではCLIP類似度でフィルタリングを行う実例があり、低類似度が“ノイズ対”である可能性を示唆します。citeturn9search3turn9search16  
- トークン長超過率  
  - **>10%**：学習でタグが切れている画像が目立つ（黄）  
  - **>30%**：分布評価そのものが歪む（赤）  
  77 tokens を超えると切り捨てられる前提があるため、超過率は実害を持つ。citeturn12search3turn8search15  

## 指標から導く具体的な推奨アクション例

ここでは「ユーザーに見せると、そのまま作業に移れる」粒度で、よくあるパターンと介入例を示します（“例”なので、最終判断は目的次第）。

**例A：単一タグが支配（M5が赤、M3/M4も悪化）**  
- 観測：Top‑1 share が 55%、HHIが高い、エントロピーが低い。citeturn4search6turn0search0  
- 解釈：学習信号が1タグに寄り、生成がその要素に引きずられる（不均衡データが問題になり得るという指摘と整合）。citeturn10search2  
- 推奨：  
  - そのタグが“常に真”なら **暗黙属性としてタグから外す**（例：全画像がportraitなら `portrait` を外す）。  
  - 本当に必要なら **不足側の画像を追加**、または **多数側（支配側）を間引く/繰り返し回数を下げる**。  
  - 学習ツール側でタグをランダムに落とす運用（caption_tag_dropout）も“偏り緩和の手段”になり得る。citeturn11search13turn11search15  

**例B：上位10で80–90%を占める（M5黄〜赤、M1も低下）**  
- 観測：Top‑10 mass が極端に高い。  
- 解釈：データセットが狭すぎる/粒度が粗すぎる/自動タグが同じ語彙に固定されている。  
- 推奨：  
  - 自動タグ生成を使っているなら、モデル/辞書を変えて語彙を増やす。  
  - 目的が「特定スタイルLoRA」なら、逆に“狭いのはOK”の可能性もあるので、UI上は「用途により正常」も併記。

**例C：低IDFタグが多すぎる（M7で“ストップタグ候補”が大量）**  
- 観測：`(highly frequent, low idf)` タグが大量で、画像間の差を説明していない。citeturn0search2  
- 解釈：学習テキストが“いつも同じ”→生成時に制御レバーが少なくなる。  
- 推奨：  
  - 低IDFタグを **候補として一覧提示**し、「削除/保持/まとめる（正規化）」をユーザーに選ばせる。  
  - “常に真”のものは暗黙化、“重要だが一般的”なもの（例：`portrait`）は維持、などのガイドを添える。

**例D：単発タグが多すぎる（M7で超高IDFが多い、M1が過大に見える）**  
- 観測：出現1回のタグが膨大。  
- 解釈：表記ゆれ/誤字/ノイズ（ランダム文字列）/過剰に細かいタグ付け。  
- 推奨：  
  - 正規化（小文字化、記号統一、スペース/ハイフン統一）  
  - 同義語クラスタリング（簡易版なら “編集距離が近いもの” を候補提示）  
  - 出現回数が閾値未満（例：<3）のタグは **一括で“検討リスト”**へ

**例E：不自然な強共起が検出（M8赤）**  
- 観測：PMI/Liftが極端に高いペアが、意味的に不自然。citeturn2search7turn6search3  
- 解釈：収集バイアス（同じ投稿者/同じシリーズ）か、誤タグ混入。  
- 推奨：  
  - そのペアが出る画像サンプルを数十枚抽出し、目視レビュー（プロダクトなら“レビューキュー”を作る）。  
  - どちらかが本当は別カテゴリの代理ラベルなら、タグ付けルールを修正。

**例F：共起グラフが2〜3コミュニティに強く分割（M9赤）**  
- 観測：モジュラリティ最大化で明確な塊、コミュニティ間のエッジが少ない。citeturn2search2turn2search6  
- 解釈：データが複数カテゴリ（例：屋内/屋外、写実/アニメ、昼/夜）に分かれている。単一LoRAに押し込むと“混ざった概念”を作りやすい。  
- 推奨：  
  - **データセット分割**（コミュニティごとに別LoRA）  
  - または **トリガータグ（カテゴリ識別子）を明示的に付け**、生成時に選べるようにする（製品のUXとして有効）。  
  - kohya系ではカンマ区切りキャプションをシャッフルして学習するオプションがあるため、順序依存が疑われる場合に併用も検討。citeturn11search15  

**例G：近重複率が高い（M10赤）**  
- 観測：pHash等で、ハミング距離が小さいクラスタが多い。perceptual hashが近重複検出に使われることは一般的。citeturn3search1turn1search3  
- 解釈：枚数水増しでタグ分布が歪み、同じ構図を強く記憶させやすい。  
- 推奨：  
  - クラスタごとに代表画像を1〜数枚だけ残す（多様性優先）。  
  - “連写”は残してもよいが、重みを下げる（サンプリング確率をクラスタサイズの逆数にする）。

**例H：画像‐タグ整合性が低い外れ値が多い（M11赤）**  
- 観測：CLIPScore/類似度が下位に偏り、下位10%が極端に低い。CLIPScoreは参照なし評価として提案され、CLIP類似度フィルタも実運用されている。citeturn9search0turn9search5  
- 解釈：誤タグ、取り違え、タグが情報不足、あるいは画像が目的外。ノイズ対が学習を難しくする問題意識とも一致。citeturn10search1  
- 推奨：  
  - 低スコア画像を“要確認”に回し、削除/再タグ付け/再キャプション。  
  - 自動キャプションが原因なら、別モデルで再生成し比較（製品なら“再生成候補”を提示）。

**例I：トークン長超過率が高い（M11赤）**  
- 観測：77 tokens超過が頻発（Stable Diffusion系の一般的制約として説明される）。citeturn12search3turn8search15  
- 解釈：後半タグは学習に入っていない＝分布分析も意味が薄い。  
- 推奨：  
  - “重要タグだけ残す”ために、低IDFタグを削る（M7と連動）。  
  - 重要な先頭タグを固定する運用や、シャッフル設定の見直し（順序依存対策）を検討。citeturn11search15  
  - 対象パイプラインが最大長拡張をサポートする場合は、その設定を製品側で案内（ただしモデル依存である点に注意）。citeturn8search3  

## 実装メモと運用ヒューリスティクス

製品実装を想定した、実務上の落とし穴と回避策です。

- **小さいデータセット（数十〜数百枚）では、分布推定の分散が大きい**  
  エントロピーやJSDは見かけの変動が大きくなるので、(a) 最低枚数未満は“参考値”表示、(b) ラプラス平滑などでゼロ頻度を回避、(c) ブートストラップで信頼区間を出す、などの工夫が有効です（ここは統計的実装論の領域）。  
- **JSDをデフォルトにする理由**  
  KLは \(q(t)=0\) 問題で無限大になり得る一方、JSDは対称で有限という特性があり、プロダクトの“落ちない”設計に向きます。citeturn2search0turn2search1  
- **共起系（M8/M9）は“レアタグ対策”が必須**  
  PMI/Liftはレアに過敏になりやすいため、最低出現数フィルタを入れるべきです。Liftの注意点として「稀なアイテムでLiftが非常に高くなる」ことが講義資料レベルでも明示されています。citeturn6search3  
- **CLIPScoreは強いが万能ではない**  
  参照なし評価として高い相関が報告される一方、細かな意味の取り違えなどで弱点があるという検証もあります。製品では「下位外れ値の検知」に寄せると安全です。citeturn9search0turn9search7  
- **学習ツール側の“介入オプション”を提案に接続する**  
  kohya系ドキュメントには、カンマ区切りキャプションをシャッフルするオプションや、caption dropout / tag dropout に関する設定が記載されています。ヘルススコアの“改善ボタン”として繋げやすい領域です。citeturn11search15turn11search13  

以上をまとめると、消費者向けの「Dataset Health Score」は、(1) 偏り（M1–M5）、(2) ターゲット適合（M6）、(3) 識別性（M7）、(4) 共起構造（M8–M9）、(5) 重複（M10）、(6) 整合性＋実効長（M11）を**過不足なく、しかし過度に複雑化せず**統合するのが実務的です。