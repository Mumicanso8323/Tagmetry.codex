# Stable Diffusion LoRA学習の失敗モードと不安定化パターンのデータセット起因マップ  
（SD1.5 / SDXL、タグ・統計・簡易メタデータだけで検知できる範囲にフォーカス）

## 前提とスコープ

LoRAは「事前学習済みの拡散モデル（主にU-Netのクロスアテンション等）に、小さな追加パラメータを挿入して微調整する」ためのパラメータ効率の良い手法で、フル微調整より小さな計算資源で概念（人物・キャラ・物体・画風など）を学習できることが広く使われています。citeturn13view1turn4view0

SDXLはSD1系より大きいU-Netと**2つのテキストエンコーダ**を使い、複数アスペクト比も含めて学習された世代で、実運用でも「おおむね1024px付近が得意」という前提が効きます。citeturn10view0turn6view0turn5view1  
特にentity["company","Hugging Face","ml platform"]のDiffusersドキュメントでは、**多くのSDXLチェックポイントは1024×1024が最適で、768/512も動くが品質が落ち、512未満は推奨しない**と明記されています。citeturn6view0

本レポートの中心は「学習がうまくいかない／不安定／意図しない挙動になる」現象を、**データセットの統計**（枚数、解像度・縦横比分布、重複、タグ分布、共起、キャプション長、欠損など）と**タグ（キャプション）**から説明し、**推論モデルによる重い解析なし**に実装できる検知・提案（Tagmetryのようなツールが実装しやすいルール）へ落とすことです。  
なお、最終症状（例：出力が崩れる、色が変わる）そのものは本来「生成して確認」が必要ですが、ここでは**“症状が起きやすいデータ構造”を推定**することに重点を置きます（推定であることがある点は明示します）。citeturn25view0turn20view0turn23view0

---

## 失敗モードのタクソノミー

LoRA学習の失敗は、大きく「何が壊れるか（現象）」と「なぜ壊れたか（原因）」で整理すると、データセット起因の検知が作りやすくなります。

**現象（症状）ベースの分類**

- **過学習・記憶（memorization）／多様性低下**  
  学習画像の構図・表情・ポーズに“スナップ”して新規性が落ちる、同じ背景要素が出続ける、学習画像に近いものが出やすい。少数画像を長く学習すると多様性が落ちやすいことは、DreamBooth系の議論で明確に指摘されています。citeturn32view0turn27view0

- **概念ブリード（concept bleed）／クラス乗っ取り（class hijacking）／言語ドリフト（language drift）**  
  本来は汎用語（例：「man」「dog」など）で出るべき一般概念が、特定個体に引っ張られる・混ざる。DreamBooth論文は「言語ドリフト」や「学習しすぎで多様性が落ちる」問題を明示し、prior preservationで緩和できると述べています。citeturn32view0  
  “concept bleeding”という現象自体も、SDXLの制限として言及され、複数概念の干渉として研究対象になっています。citeturn16search1turn16search3

- **アイデンティティ崩壊（identity collapse）／学習不足（underfitting）**  
  そもそも被写体の同一性を安定して再現できない（顔が別人化、特徴が保持されない）。近年の微調整研究でも、拡散モデルの個体学習は「underfitting（同一性を掴めない）」と「overfitting（記憶して背景多様性が死ぬ）」の両極が主要課題として整理されています。citeturn27view0turn32view0

- **プロンプト感度（prompt sensitivity）／トリガー依存（trigger lock-in）**  
  “特定トリガーワードがないと出ない / 逆にトリガーが強すぎてどんなプロンプトでも混入する”。キャプションがノイズだらけ・構造が不統一だと、モデルが“プロンプト順序や書式”に過度依存しやすいという視点は、構造化キャプション研究の主張と整合します。citeturn23view0turn20view0turn14view0  
  さらに、よく使われるレアトークン例（“sks”）が別意味を持ち得ること、トリガー語選定が結果に影響することもコミュニティ実践で強調されています。citeturn13view0turn30view0turn32view0

- **色・画風・質感のドリフト（color/style drift）**  
  コントラストが過剰、粒状ノイズが増える、全体がスムース化する、画風が勝手に固定されるなど。実験ブログでは、正則化画像の“質（例：refiner無しでスムース寄り）”が生成品質の癖として学習結果に反映される例が報告されています。citeturn19view0  
  研究側でも、微調整による“appearance drift”が問題として整理されています（※ここは一般論で、データセット統計による推定が中心になります）。citeturn29search19

- **学習不安定（loss spike / NaN / 急崩壊）**  
  lossが突然NaNになりブラック画像化する等は、実装・精度設定・最適化周りで実際に報告されています。citeturn24view0turn18view0  
  一方、拡散モデルは学習データの外れ値・破損に脆い、という学術的整理もあり、データ側の外れ値が不安定化に寄与し得ます。citeturn25view0turn20view0

---

## 失敗モード別の原因と緩和策

以下は、各失敗モードを「データセット（タグ・統計）起因」「学習起因」「実用緩和策」に分解し、さらに**Tagmetryのようなツールが“データだけで拾える信号”**を併記します。

### 過学習・記憶／多様性低下

**症状**  
同じ構図・同じ背景・同じ配色に寄る、プロンプトで視点や背景を変えにくい、学習画像に近い出力を繰り返す。少数画像を長く学習した際に“few-shot viewへスナップ”するリスクはDreamBooth論文が具体例込みで指摘しています。citeturn32view0

**データセット（タグ・統計）起因**  
- **重複・近重複（duplicates / look-alikes）が多い**：同一・近似画像が多いと“実効サンプル数”が減り、記憶寄りになります。拡散モデルの「近重複（near-duplicates）の数 k が小さいのに抽出可能＝問題的な記憶」になり得る、という議論はデータ抽出研究で明示されています。citeturn33view0  
- **画像多様性が低い（ポーズ・背景・照明が固定）**：タグ上も「背景・構図タグのエントロピーが低い」「同じ共起集合が並ぶ」などで検知できます（後述のチェックリスト参照）。DreamBooth系の個体学習は、少数画像のため背景や文脈に過適合しやすいことが繰り返し論点化されています。citeturn32view0turn30view0turn25view0  
- **キャプションが単一テンプレに偏りすぎ**：同じ書式を過学習する（＝プロンプト依存が増える）可能性があります。キャプション構造の一貫性は有用ですが、同一テンプレの繰り返しは“文章構造への過適合”を誘発し得るため、構造化の研究でも「構造のメリット」一方で「固定構造で学習すること自体が学習分布を規定する」点が論じられています（※ここは利点側の主張が中心）。citeturn23view0turn30view0

**学習起因**  
- **学習しすぎ（steps/epochs/repeatsが過大）**：少数データでは特に“長く回すほど”多様性が落ちやすい。citeturn32view0turn27view0  
- **rank（network_dim）が過大**：表現力が高いほど小データでは覚え込みやすい（一般的傾向）。kohyaの解説でもrankが表現力と計算・容量を増やすパラメータであることが明記されています。citeturn4view0  
- **text encoder まで強く学習**：プロンプト解釈自体が変質しやすく、汎用性が落ちる方向に働くことがあります（特に小データ）。

**実用緩和策（データ中心）**  
- **近重複除去（exact/near-dup）→実効サンプル数を増やす**：まず最も効く“データの水増し”です（ハッシュで検知可能）。citeturn33view0turn25view0  
- **背景・構図の分散を意図的に上げる**：同一被写体でも、背景、距離、画角、照明を変える。DreamBooth系で背景に引っ張られる典型を踏まえ、正則化（後述）だけでなく“入力自体の多様化”が根本対策になります。citeturn32view0turn30view0  
- **キャプションのシャッフル／タグドロップアウト**：kohyaのデータ設定は `shuffle_caption` や `caption_tag_dropout_rate` 等を提供しており、タグ順序・一部欠落を学習に混ぜられます。citeturn14view0  
- **学習側は「短く試す」→良いチェックポイントで止める**：推論を伴うため本スコープ外ですが、DreamBoothでも“長くやるほど危険”が明言されています。citeturn32view0turn27view0

---

### 概念ブリード／クラス乗っ取り／言語ドリフト（concept leak）

**症状**  
- 「man」「dog」などのクラス語だけで特定個体が出る（クラス乗っ取り）  
- 複数概念で属性が混ざる（concept bleed）  
- “一般概念を生成する能力”が落ちる（言語ドリフト）citeturn32view0turn16search1turn16search3

**データセット（タグ・統計）起因**  
- **インスタンス語（トリガー）とクラス語が常にセット**：例「[trigger] man」が全キャプションに入り、さらに“背景語”も常に一緒だと、トリガーが背景まで含む“画像全体”に結びつきやすい、というデータ中心の指摘があります。citeturn30view0  
- **正則化（prior-preservation/regularization）相当の“非インスタンス例”が不足**：DreamBoothのprior preservationは、クラスの事前分布を保持してドリフトや多様性低下を抑える目的で導入されています。citeturn32view0  
- **タグの共起が“分離不能”**：トリガーが常に「特定背景タグ」「特定衣装」等と共起している（条件付き確率が極端）と、分離が難しく漏れやすい（これは統計で検知可能、後述）。データ観点の研究でも「簡素なプロンプト（a [class noun]）だけだと、前景/背景の区別がつかず、tokenが画像全体に結びつく」と説明されています。citeturn30view0  
- **マルチ概念LoRAで、概念A/Bのタグ分布が強く重なる**：概念ごとの識別信号が弱いと干渉しやすい（推定）。

**学習起因**  
- **学習しすぎ**：DreamBooth論文は「学習を長くすると言語ドリフト・多様性低下に繋がる」ことを述べ、prior preservationで“より長く学習できる”としています。citeturn32view0  
- **text encoder を強く学習**：クラス語の埋め込み付近が動くと、クラス語の意味が乗っ取られやすい（経験則）。  
- **キャプション（タグ）の扱い**：`keep_tokens`（先頭固定）やprefix/suffixの付け方次第で、どの語が“常に強い条件”になるか変わります。citeturn14view0

**実用緩和策（データ中心）**  
- **prior preservation / regularization を“データ的に強化”**  
  DreamBoothは「a [class noun]」の正則化画像を提案しましたが、後続研究は「プロンプトが単純すぎると効果が弱い」「背景・属性まで含めた構造化プロンプトで正則化画像を作ると、より長く学習しても過学習しにくく、同一性とテキスト整合が改善する」と主張しています。citeturn30view0turn32view0  
- **“背景語を含むキャプション”で、トリガーを前景に結びつける**  
  具体的に「a [identifier] [class] [background]」のように背景を明示し、正則化側も同形式で増やすことで、identifierが画像全体ではなく対象に結びつきやすい、というデータ中心提案があります。citeturn30view0  
- **トリガー語の選定を見直す（既存意味の衝突回避）**  
  HFの実践ガイドでは、よく使われるレアトークン例（“sks”）が実は別の意味（武器ブランド）と結びつく可能性があると注意喚起されています。citeturn13view0  
  DreamBooth論文も「識別子は弱い事前（rare token）」が望ましいという方向性を説明しています。citeturn32view0  
- **タグ共起の“解きほぐし”**（後述の共起警告が出たら）  
  背景・衣装・画風タグを一部の画像だけで変える／削る、あるいは概念を分割して別LoRAへ、が現実的です（推定だが、データ中心研究の説明と整合）。citeturn30view0turn20view0

---

### アイデンティティ崩壊／学習不足（underfitting）と“過学習型”崩壊の二極

**症状**  
- underfitting：トリガーを入れても別人、特徴が安定しない  
- overfitting型：トリガーを入れると“似過ぎる”が、背景多様性が死ぬ、プロンプト無視が増えるciteturn27view0turn32view0turn30view0

**データセット（タグ・統計）起因**  
- **同一人物/キャラが混ざっていないか**：タグ上「複数の固有名／識別タグが混在」「性別・年齢・髪色などが矛盾」などは、同一性学習を難しくします（推定だが、条件ノイズが性能を劣化させるという一般論と整合）。citeturn20view0  
- **顔アップ偏重・同じ画角偏重**：身体・髪・衣装など“同一性の手掛かり”が欠ける/固定化する。DreamBoothは少数データでの“view/poseのスナップ”を指摘しており、同一性を保ちながら多様に出すのが難しい背景があります。citeturn32view0turn27view0  
- **ラベル（タグ）不足**：背景・視点・表情などの条件語が雑だと、同一性と属性の分離に失敗しやすい（推定）。

**学習起因**  
- **rankが小さすぎる／学習が浅すぎる**：表現力不足。rankは表現力に直結するため、低すぎると学習不足に寄ります。citeturn4view0  
- **text encoder 学習の強弱**：TEを全く学習しないと“トリガー語が埋め込み空間に定着しにくい”ケースがある一方、学習しすぎると汎用語が壊れます（トレードオフ）。SDXLではTEが2つあり、LRも2系統に分ける設定が一般化しています。citeturn5view1turn4view0

**実用緩和策（データ中心）**  
- **“同一性に効く多様性”を増やす**：表情・髪型・服・距離・照明を散らしつつ、本人（対象）だけは一貫させる。これはDreamBooth系の「少数データで多様に生成したいが、学習しすぎるとスナップする」問題設定と一致します。citeturn32view0turn27view0  
- **キャプションを“前景/背景/属性”に分割して記述**：研究では、背景語を入れた正則化戦略が「識別子が画像全体に結びつく」問題を抑えると述べています。citeturn30view0  
- **正則化（regularization）を“多様に・高品質に”**：実験ブログでは、正則化画像がスムース寄りだと、その傾向が結果に反映され得ることが示唆されています。citeturn19view0

---

### プロンプト感度／トリガー依存（タグ・キャプション整合の破綻）

**症状**  
- 語順が変わるだけで出たり出なかったりする  
- “特定の言い回し”でしか動かない  
- 長いタグ列の後半が効いていないように見える（※トークン制限・切り捨ての可能性）

**データセット（タグ・統計）起因**  
- **キャプションがノイズ・不統一**：大規模データのalt-textのように“構造がバラバラだと制御が難しい”という問題意識は、構造化キャプションの研究で明示されています。citeturn23view0  
- **条件（タグ）が間違っている／矛盾している**：条件ノイズ（ラベル破損）が条件付き拡散の性能を大きく劣化させる、という研究結果があります。citeturn20view0  
- **トークン長の問題（切り捨て）**：kohyaの学習では `max_token_length` の設定が絡み、長いキャプションでの学習は注意が必要です（拡張は150/225が例示される一方、不要なら75推奨という注意もあります）。citeturn28search18turn18view0  
  「重要タグが後方に追いやられて切り捨てられる」データセットは、プロンプト感度・不安定条件付けの温床になります（推定）。

**学習起因**  
- **caption shuffle / dropout を使わず“固定タグ列”で学習**：書式への過適合が起きやすい（推定）。  
  kohyaの設定は `shuffle_caption` や `caption_dropout_rate` / `caption_tag_dropout_rate` を提供しています。citeturn14view0turn28search23  
- **トリガー語の選定ミス（既存意味の混入）**：HFは“sks”例を警告しています。citeturn13view0

**実用緩和策（データ中心）**  
- **キャプション品質の底上げ**：最低限「前景（主体）」「クラス」「背景」「重要属性（髪/服/色/画角）」を揃える。構造化キャプションは“学習を簡単にし、制御性を上げる”という主張があり、乱雑なキャプションより整合性が得やすい方向です。citeturn23view0  
- **“重要タグを先頭固定”＋残りをシャッフル/ドロップ**：`keep_tokens` と `shuffle_caption`、さらにtag dropoutを組み合わせる戦略が取りやすいです。citeturn14view0  
- **トークン長監査（後述）→短縮・再構成**：タグが長いほど、環境によっては切り捨てが起きます。kohya側の長さ拡張はありますが、拡張仕様差の注意があります。citeturn28search18turn18view0

---

### 色・画風・質感のドリフト（style/color drift）

**症状**  
- コントラスト過剰、粒状ノイズ、過度なスムージング  
- 画風タグを入れていないのに画風が固定化  
- “色がにじむ／別対象に色が移る”のような混線（広義のbleed）

**データセット（タグ・統計）起因**  
- **画風・画質タグがほぼ全画像で同一**：例「masterpiece, best quality, …」が常にprefixとして入ると、その“画風条件”が実質的に常時オンになります（推定）。kohya設定には caption_prefix/suffix があり、全サンプルに共通語を付加できます。citeturn14view0  
- **正則化画像・教師画像の品質差**：実験ブログでは、refiner無しで生成した正則化画像の“スムース傾向”が学習結果に増幅され得る、と解釈されています。citeturn19view0  
- **色・照明タグの矛盾/不足**：同一タグで色が大きく違うなどは、条件ノイズとして挙動を不安定化し得ます。citeturn20view0  
- **概念共起の固定（例：トリガーと“特定の色”が常に共起）**：色がアイデンティティに誤結合し、プロンプトで色を変えにくくなる（推定）。

**学習起因**  
- **学習しすぎ／rank過大**：ちょっとした偏り（色味・シャープネス）まで吸い上げて固定化しやすい（推定）。  
- **augmentationの扱い**：color augmentationはデータ側の偏りを均す可能性がある一方、意図しないドリフトもあり得る（慎重に）。

**実用緩和策（データ中心）**  
- **画風語（品質語）を“必要最小限”にする**：常時オンにしたい条件でないなら、prefix固定は避けるか、tag dropoutで確率的に落とす。citeturn14view0turn28search23  
- **正則化画像の生成品質（分布）を教師側に合わせる**：少なくとも“教師が写真なのに正則化がスムース生成写真”のような分布差は避ける、という経験的示唆があります。citeturn19view0turn30view0  
- **色・照明のタグを整理し、矛盾を減らす**：条件ノイズの一般的害として整理できます。citeturn20view0

---

### 学習不安定（loss spike / NaN / 急崩壊）

**症状**  
lossが突然NaNになり、以降回復しない／黒画像化など。Diffusersでの学習でも「減っていたlossが突然nanになる」報告があります。citeturn24view0

**データセット（タグ・統計）起因（推定を含む）**  
- **壊れ画像・極端な外れ値・破損**：拡散モデルは外れ値に脆いという整理があり、データ外れ値が不安定性に寄与し得ます。citeturn25view0  
- **“同一キャプションで微妙に違う画像”が大量（look-alikes）**：データ汚染研究は「同一キャプションで微妙に違う画像（look-alikes）が学習を壊す/脆弱性になる」趣旨を述べています。citeturn25view0  
- **キャプションが極端に長い／トークン処理が不整合**：kohya issueでは「特定設定（max_token_length等）でNaNになった」という報告もあり、長さや設定の組み合わせが不安定要因になり得ます。citeturn18view0turn28search18

**学習起因（データ以外だが実務上重要）**  
- **精度設定・optimizer・alpha/dim整合**：kohya issueでは「alphaがdimと一致しないとNaN」など具体例が共有されています。citeturn18view0  
- **mixed precision / ライブラリ差**：forumsではfp32やxformers無効で改善した例も報告されています。citeturn24view0

**実用緩和策（データ中心）**  
- **データ健全性チェック（壊れ画像、極端サイズ、欠損キャプション）を自動化**：後述チェックリストの“構造検査”でかなり拾えます。citeturn25view0  
- **外れ値の隔離（例：圧縮が極端、極小/極大、縦横比が極端）**：拡散が外れ値に脆い整理に沿った対処です。citeturn25view0

---

## データセット統計・タグのみで実装できる検知チェックリスト

ここからは「Tagmetryが **“画像＋タグ＋簡易メタデータ（解像度、ファイル形式、サイズ、EXIF等）だけ”** で実装できる」ことに限定したチェック項目です。各項目は、可能なら「計算できる指標」「アラートの意味」「帰結しやすい失敗モード」をセットにします（閾値は環境依存なので**推奨値＝ヒューリスティック**として提示します）。

### 入力の健全性（壊れデータ・欠損）

- **読み込み不能・デコード失敗・サイズ0**：即エラー（学習不安定の温床）。外れ値・破損に拡散が脆いという整理に沿う。citeturn25view0  
- **キャプション欠損率（captionファイル無し、空文）**：LoRA学習は通常「画像とキャプションのペア」を前提にするため、欠損が多いと条件付け学習の品質が落ちる。kohya設定でもcaption_extension等が前提になっている。citeturn14view0turn15view0  
- **文字コード・区切りの異常**：`caption_separator` 等で区切りを指定できるが、データ側が混在するとタグ解析が壊れる。citeturn14view0

### 解像度・縦横比・フォーマット分布

- **解像度の分布がベースモデルと不整合**  
  - SDXL：短辺512未満が多い／1024近傍が少ない → 品質低下リスク。citeturn6view0turn5view1  
  - SD1.5：基本512近傍が前提になりやすい（一般論）。  
- **極端な縦横比の比率**：bucketing（`enable_bucket`）が前提でも、極端ARが多いと学習が不安定化・有効バッチが小さくなりやすい（推定）。kohyaはbucket関連オプションを提供。citeturn14view0turn5view1  
- **フォーマット混在（PNG/JPEG、アルファ有無、極端圧縮）**：メタデータとして警告。圧縮ノイズや透過境界は“学習してほしくない特徴”になり得る（推定）。

### 重複・近重複（最重要：実効データ枚数の推定）

- **exact duplicate（バイト一致）率**  
- **near duplicate（pHash/dHash等の知覚ハッシュ＋ハミング距離閾値）率**  
  知覚ハッシュは「見た目が近い画像に近いハッシュを出す」設計で、dHashのようにハッシュ差（ハミング距離）で類似判定できる。citeturn35search0turn35search13turn35search7  
- **クラスター化（同一/近似画像が何枚束ねられるか）**  
  “k個の近重複”がある場合に記憶性の解釈が変わる、という観点が拡散モデルのデータ抽出研究でも明示されています（kが小さいのに抽出可能＝問題的）。citeturn33view0  

**アラート例（ヒューリスティック）**  
- near-dupクラスター（≥3枚）の画像が全体の10–20%を超える → **過学習・記憶・多様性低下**リスク高  
- 1つのクラスターが全体の2–5%を占める → **“同一構図固定”**が強く出やすい

image_group{"layout":"carousel","aspect_ratio":"16:9","query":["perceptual hashing dHash duplicate image detection example","tag frequency long tail distribution chart example","image dataset duplicate cluster visualization"],"num_per_query":1}

### タグ語彙・頻度分布（偏りと“学習したい概念”の分離性）

- **語彙サイズ（ユニークタグ数）**、**タグ頻度のロングテール度**（Gini、上位kタグの占有率など）  
  概念分布の偏りがモデルの概念応答を壊す（tailがheadに引っ張られる）という問題は拡散モデルの不均衡研究で体系化されています。citeturn31search0turn31search23  
- **トリガータグ（identifier）の頻度と共起**  
  - identifierが**常に同じ画風語・背景語と共起**している → **背景巻き込み／クラス乗っ取り**のリスク（後述の共起チェックへ）citeturn30view0turn32view0  
- **タグのエントロピー（分散）**  
  - 背景タグ、画角タグ、照明タグがほぼ固定（エントロピー低） → **背景過適合**のリスク（推定）citeturn32view0turn30view0

### タグ共起（“結びつき過ぎ”の検知）

実装しやすく効果が高いのは「条件付き確率」で、例えば以下を自動計算します。

- **P(tag_B | identifier)** が極端（例：0.95以上）  
- **PMI / NPMI**（正規化相互情報量）で強結合を抽出  
- **identifierごとの“共起上位n語”を比較**（マルチ概念LoRAなら、概念間で共起語がほぼ同じ＝分離不能）

この強結合は「identifierが前景ではなく画像全体（背景含む）に結びつく」問題設定と整合し、正則化プロンプトの構造化で改善できるというデータ中心提案があります。citeturn30view0turn32view0

### 矛盾・ノイズ（条件の破損）チェック

- **同一キャプション内の矛盾語**（例：`day`と`night`、`indoor`と`outdoor`等）  
- **同一画像の複数キャプションが不一致**（ファイル名揺れ・重複画像でタグが違う）  
- **同義語の乱立（正規化不足）**：`t-shirt` / `t shirt` / `tee shirt` など  
条件ノイズが条件付き拡散の性能を著しく劣化させる、という研究整理に沿ったチェックです。citeturn20view0turn23view0

### キャプション長・トークン長（切り捨て）監査

- **タグ数／推定トークン数の分布**  
  - しきい値（例：75相当）超が多い → 後方タグが切り捨てられるリスク（環境次第）  
- **“重要タグが後ろに偏る”度合い**：頻出重要語が末尾側に多いと、切り捨て時に学習されにくい  
kohyaでは `--max_token_length`（デフォルト75）を150/225へ拡張して学習可能だが、不要なら75推奨・仕様差注意、という説明があります。citeturn28search18turn18view0

### “正則化（reg）相当”の不足をデータ側から推定

DreamBooth文脈のprior preservationは、言語ドリフトと多様性低下を抑えるために導入されました。citeturn32view0  
Tagmetryが推定できる信号としては：

- **クラス語（man/dog等）が常に含まれ、かつ“非identifier例”がゼロ**：クラス乗っ取りリスク  
- **背景語が常に固定**：背景巻き込みリスク  
- **“identifier以外の多様性語”が少ない**：多様性低下リスク  

加えて、より新しいデータ中心研究は「単純な正則化プロンプトでは不十分で、背景や属性を含めた構造化正則化が過学習を抑え、同一性・テキスト整合を改善する」と述べます。citeturn30view0

---

## 推奨プレイブック

ここでは「ユーザーが観測した症状（A）」＋「データセット統計・タグ信号（B/C）」から、**データ修正**と**学習設定修正**を提案する“ルール”をまとめます。Tagmetry側は、症状入力がなくても「信号だけで事前警告＋推奨」を出せます。

### 過学習っぽい（似た構図ばかり・多様性が死ぬ）

- **症状A**：出力が学習画像に近い／背景が固定／視点が変わらない  
- **信号B/C（データ）**：near-dup率が高い、背景タグのエントロピーが低い、identifierと背景タグの共起が極端  
- **推奨X（データ）**：  
  - near-dupを削る（まず最優先）citeturn33view0turn35search0  
  - 背景・画角・照明のタグ分散を上げる（データ追加/置換）citeturn32view0turn30view0  
- **推奨Y（学習）**：  
  - repeats/epochs/stepsを下げ、チェックポイントで早期停止（原理的注意）citeturn32view0turn27view0  
  - `shuffle_caption`＋`caption_tag_dropout_rate` を使い、固定テンプレ過学習を避けるciteturn14view0turn28search23  
  - rankを下げる（過剰表現力を抑える）citeturn4view0  

### クラス乗っ取り（「man」だけで本人が出る）／概念漏洩

- **症状A**：クラス語だけでも個体が出る、個体がどのプロンプトにも混入  
- **信号B/C（データ）**：`[identifier] [class]` が全captionで固定、非identifier例が不足、identifierと背景語が常時共起  
- **推奨X（データ）**：  
  - **正則化（reg）を追加**：DreamBoothが提案したprior preservationの狙いに沿うciteturn32view0  
  - 可能なら「背景語を含む構造化正則化」へ：identifierが“画像全体”に結びつく問題を抑える、というデータ中心提案citeturn30view0  
  - 共起が強すぎる背景語・画風語を間引き、概念を分離可能にする（推定だが原理整合）citeturn30view0turn20view0  
- **推奨Y（学習）**：  
  - TE学習を弱める／まずはU-Net中心にする（プロンプト意味の崩壊を抑える方向、トレードオフ）citeturn5view1turn4view0  

### トリガー依存・プロンプト感度が強い

- **症状A**：語順や言い回しで激変／特定書式のみ反応  
- **信号B/C（データ）**：タグ書式がバラバラ、矛盾タグが多い、キャプション長が長く切り捨てリスク  
- **推奨X（データ）**：  
  - キャプションを“構造化”し、最低限のフィールド（主体/背景/属性）を揃える：構造化により制御性が上がるという研究主張citeturn23view0  
  - 矛盾・同義語揺れを正規化：条件ノイズは条件付き拡散を劣化させるciteturn20view0  
  - 重要タグを先頭に寄せる（keep_tokens設計）＋残りをシャッフル/ドロップciteturn14view0  
  - 75相当超のキャプションが多いなら、短縮かmax_token_length設計を再検討（拡張の注意含む）citeturn28search18turn18view0  
- **推奨Y（学習）**：  
  - `shuffle_caption`＋dropoutを有効化し、書式過適合を緩和citeturn14view0turn28search23  

### SDXLなのに“なんとなく弱い／崩れる”

- **症状A**：精細感が出ない、解像に引っ張られる  
- **信号B/C（データ）**：解像度分布が低すぎる（短辺512未満が多い）、縦横比が極端、1024近傍が少ない  
- **推奨X（データ）**：  
  - SDXL前提なら高解像データを確保（少なくとも“多くが1024に近い”）citeturn6view0turn5view1  
  - bucketing前提の縦横比分布を整える（極端ARの割合を下げる）citeturn14view0turn5view1  
- **推奨Y（学習）**：  
  - SDXLはTEが2つなのでLRを分ける設定を適切に（lr1/lr2）citeturn5view1  

### lossがスパイクしがち／NaNになりやすい

- **症状A**：lossが突然NaN、黒画像化等 citeturn24view0  
- **信号B/C（データ）**：壊れ画像、極端外れ値、同一キャプションlook-alikesが多い  
- **推奨X（データ）**：  
  - 壊れ画像・極端サイズ・極端圧縮を隔離（外れ値に脆い）citeturn25view0  
  - 重複/near-dupを削り、look-alikesの密集を下げるciteturn25view0turn33view0  
- **推奨Y（学習）**：  
  - alpha/dim整合、max_token_length等の“壊れやすい組合せ”を避ける（報告例あり）citeturn18view0  

---

このレポートは「データセット＋タグ＋簡易メタデータ」で推定できる失敗要因に絞りました。特に、**近重複検出（実効枚数の推定）**、**タグ共起（identifierと背景/画風の強結合）**、**キャプション長（切り捨て）**、**矛盾/ノイズ**の4点は、LoRA学習の代表的な破綻（過学習・漏洩・プロンプト感度・不安定化）に直結しやすく、しかも推論不要で自動化しやすい“高ROI”領域です。citeturn33view0turn30view0turn23view0turn20view0